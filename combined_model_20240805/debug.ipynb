{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('/home/shiqi/code/Project2-sensor-case/model_combination_Argos/utils')\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "from load_dataset import cut_slices, load_dataset\n",
    "from sklearn.decomposition import PCA\n",
    "import copy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/home/shiqi/code/Project2-sensor-case/model_combination_Argos/combined_model_20240805/outputs/experiment_1/config.yaml'\n",
    "config = read_config_file(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 150\n",
      "(149, 6957) (149, 6957) (149, 2)\n",
      "x_data shape: (6258, 6957), y_data shape: (6258, 6957), u_data shape: (6258, 2)\n",
      "PCA matrix shape: torch.Size([4, 6957])\n",
      "PCA data shape: torch.Size([6258, 4]), torch.Size([6258, 4]), torch.Size([6258, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiqi/code/Project2-sensor-case/model_combination_Argos/combined_model_20240805/train_model.py:311: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.mean = nn.Parameter(torch.tensor(mean, dtype=torch.float32), requires_grad=False)\n",
      "/home/shiqi/code/Project2-sensor-case/model_combination_Argos/combined_model_20240805/train_model.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.std = nn.Parameter(torch.tensor(std, dtype=torch.float32), requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "## Device\n",
    "device = 'cpu'\n",
    "    \n",
    "## Load data\n",
    "x_data, y_data, u_data = data_preparation(config, config['train_data_dir'])\n",
    "x_data = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "y_data = torch.tensor(y_data, dtype=torch.float32).to(device)\n",
    "u_data = torch.tensor(u_data, dtype=torch.float32).to(device)\n",
    "dataset = [x_data, y_data, u_data]\n",
    "\n",
    "## Dimension\n",
    "x_dim = x_data.shape[-1]\n",
    "u_dim = u_data.shape[-1]\n",
    "\n",
    "\n",
    "## PCA\n",
    "# Standardize data\n",
    "mean_1 = torch.mean(x_data, dim=0)\n",
    "std_1 = torch.std(x_data, dim=0)\n",
    "std_layer_1 = StdScalerLayer(mean_1, std_1)\n",
    "x_data_scaled = std_layer_1.transform(x_data)\n",
    "\n",
    "# PCA layer\n",
    "pca = PCA(n_components=config['pca_dim'])\n",
    "# Ensure x_data_scaled is converted back to a NumPy array for PCA\n",
    "pca.fit(x_data_scaled.detach().cpu().numpy())\n",
    "components = pca.components_\n",
    "pca_matrix = torch.tensor(components, dtype=torch.float32).to(device)\n",
    "print(f'PCA matrix shape: {pca_matrix.shape}')\n",
    "pca_layer = PCALayer(x_dim, config['pca_dim'], pca_matrix)\n",
    "\n",
    "# Standardize data 2\n",
    "x_pca = pca_layer.transform(x_data_scaled)\n",
    "mean_2 = torch.mean(x_pca, dim=0)\n",
    "std_2 = torch.std(x_pca, dim=0)\n",
    "std_layer_2 = StdScalerLayer(mean_2, std_2)\n",
    "\n",
    "# Build pca dataset\n",
    "x_pca_scaled = std_layer_2.transform(x_pca)\n",
    "y_data_scaled = std_layer_1.transform(y_data)\n",
    "y_pca = pca_layer.transform(y_data_scaled)\n",
    "y_pca_scaled = std_layer_2.transform(y_pca)\n",
    "mean_u = torch.mean(u_data, dim=0)\n",
    "std_u = torch.std(u_data, dim=0)\n",
    "std_layer_u = StdScalerLayer(mean_u, std_u)\n",
    "u_data_scaled = std_layer_u.transform(u_data)\n",
    "dataset = [x_pca_scaled, y_pca_scaled, u_data_scaled]\n",
    "print(f'PCA data shape: {x_pca_scaled.shape}, {y_pca_scaled.shape}, {u_data_scaled.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Linear_model(config['pca_dim']+1, u_dim)\n",
    "params = Params(x_dim, u_dim, config)\n",
    "state_dict = State_Encoder(params)\n",
    "control_dict = Control_Encoder(params)\n",
    "residual_model = PCAKoopman(params, std_layer_1, pca_layer, std_layer_2, std_layer_u, state_dict, control_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_data = y_pca_scaled - linear_model(x_pca_scaled, u_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_layer_err = StdScalerLayer(torch.mean(err_data, dim=0), torch.std(err_data, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error data shape: torch.Size([6258, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f'Error data shape: {err_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pred = linear_model(x_pca_scaled, u_data_scaled)\n",
    "residual_pred = residual_model.latent_to_latent_forward(x_pca_scaled, u_data_scaled, std_layer_err)\n",
    "y_pred = linear_pred + residual_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1080.5859375\n"
     ]
    }
   ],
   "source": [
    "mse = torch.nn.MSELoss()\n",
    "loss = mse(y_pca_scaled, y_pred)\n",
    "print(f'Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_slices = cut_slices(x_pca_scaled, config['window_size'] - 1, 2)\n",
    "y_data_slices = cut_slices(y_pca_scaled, config['window_size'] - 1, 2)\n",
    "u_data_slices = cut_slices(u_data_scaled, config['window_size'] - 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_slices = torch.cat(x_data_slices, dim=0).to(device)\n",
    "y_data_slices = torch.cat(y_data_slices, dim=0).to(device)\n",
    "u_data_slices = torch.cat(u_data_slices, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slices shape: torch.Size([6216, 2, 4]), torch.Size([6216, 2, 4]), torch.Size([6216, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f'Slices shape: {x_data_slices.shape}, {y_data_slices.shape}, {u_data_slices.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(537.6321, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hybrid_loss(linear_model, residual_model, std_layer_err=std_layer_err, x_data=x_data_slices, u_data=u_data_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1: 1086.8543701171875\n",
      "Loss2: 1086.8543701171875\n"
     ]
    }
   ],
   "source": [
    "linear_pred = linear_model(x_data_slices[:, 0, :], u_data_slices[:, 0, :])\n",
    "residual_pred = residual_model.latent_to_latent_forward(x_data_slices[:, 0, :], u_data_slices[:, 0, :], std_layer_err)\n",
    "y_pred = linear_pred + residual_pred\n",
    "loss1 = mse(x_data_slices[:, 1, :], y_pred)\n",
    "print(f'Loss1: {loss1}')\n",
    "loss2 = mse(y_data_slices[:, 0, :], y_pred)\n",
    "print(f'Loss2: {loss2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
